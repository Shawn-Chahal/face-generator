Model: "disc_model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d_032 (Conv2D)          (None, 32, 32, 64)        4864      
_________________________________________________________________
layer_norm_032 (LayerNormali (None, 32, 32, 64)        128       
_________________________________________________________________
leaky_relu_032 (LeakyReLU)   (None, 32, 32, 64)        0         
_________________________________________________________________
conv2d_016 (Conv2D)          (None, 16, 16, 128)       204928    
_________________________________________________________________
layer_norm_016 (LayerNormali (None, 16, 16, 128)       256       
_________________________________________________________________
leaky_relu_016 (LeakyReLU)   (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_008 (Conv2D)          (None, 8, 8, 256)         819456    
_________________________________________________________________
layer_norm_008 (LayerNormali (None, 8, 8, 256)         512       
_________________________________________________________________
leaky_relu_008 (LeakyReLU)   (None, 8, 8, 256)         0         
_________________________________________________________________
conv2d_004 (Conv2D)          (None, 4, 4, 512)         3277312   
_________________________________________________________________
layer_norm_004 (LayerNormali (None, 4, 4, 512)         1024      
_________________________________________________________________
leaky_relu_004 (LeakyReLU)   (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_001 (Conv2D)          (None, 1, 1, 512)         4194816   
_________________________________________________________________
layer_norm_001 (LayerNormali (None, 1, 1, 512)         1024      
_________________________________________________________________
leaky_relu_001 (LeakyReLU)   (None, 1, 1, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 512)               0         
_________________________________________________________________
output (Dense)               (None, 1)                 513       
=================================================================
Total params: 8,504,833
Trainable params: 8,504,833
Non-trainable params: 0
_________________________________________________________________
